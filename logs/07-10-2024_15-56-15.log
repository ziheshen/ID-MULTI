07/10/2024 15:56:15 - INFO - __main__ - Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

Mixed precision type: no

07/10/2024 15:56:15 - WARNING - py.warnings - /shenzihe/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

07/10/2024 15:56:17 - INFO - root - freeze vision encoder
07/10/2024 15:56:20 - INFO - root - Loaded ViT-H-14 model config.
07/10/2024 15:56:25 - INFO - root - Loading pretrained ViT-H-14 weights (laion2b_s32b_b79k).
07/10/2024 15:56:27 - WARNING - py.warnings - /shenzihe/venv/lib/python3.10/site-packages/diffusers/configuration_utils.py:215: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'diffusers.schedulers.scheduling_ddpm.DDPMScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.
  deprecate("config-passed-as-path", "1.0.0", deprecation_message, standard_warn=False)

07/10/2024 15:56:27 - INFO - root - Loading pretrained model from /root/.cache/torch/hub/checkpoints/blip-diffusion
07/10/2024 15:56:27 - INFO - root - Loading pretrained BLIP2 Qformer weights.
07/10/2024 15:56:28 - INFO - root - Loading pretrained projection lyer weights.
07/10/2024 15:56:28 - INFO - root - Loading pretrained text encoder weights.
07/10/2024 15:56:28 - INFO - root - Loading pretrained vae weights.
07/10/2024 15:56:29 - INFO - root - Loading pretrained unet weights.
07/10/2024 15:56:35 - INFO - root - Using xformers.
07/10/2024 15:56:35 - INFO - root - Building datasets...
07/10/2024 15:56:35 - INFO - __main__ - 
***** Running training *****
07/10/2024 15:56:35 - INFO - __main__ -   Num examples = 4
07/10/2024 15:56:35 - INFO - __main__ -   Num batches each epoch = 2
07/10/2024 15:56:35 - INFO - __main__ -   Num Epochs = 100
07/10/2024 15:56:35 - INFO - __main__ -   Instantaneous batch size per device = 2
07/10/2024 15:56:35 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 2
07/10/2024 15:56:35 - INFO - __main__ -   Gradient Accumulation steps = 1
07/10/2024 15:56:35 - INFO - __main__ -   Total optimization steps = 200
07/10/2024 15:56:36 - WARNING - py.warnings - /shenzihe/venv/lib/python3.10/site-packages/torch/backends/cuda/__init__.py:342: FutureWarning: torch.backends.cuda.sdp_kernel() is deprecated. In the future, this context manager will be removed. Please see, torch.nn.attention.sdpa_kernel() for the new context manager, with updated signature.
  warnings.warn(

07/10/2024 15:56:38 - INFO - root - {'loss': 0.6004883646965027, 'lr': 0.0001}
07/10/2024 15:56:40 - INFO - root - {'loss': 0.2762297987937927, 'lr': 0.0001}
07/10/2024 15:56:43 - INFO - root - {'loss': 0.9983264803886414, 'lr': 0.0001}
07/10/2024 15:56:45 - INFO - root - {'loss': -0.011392168700695038, 'lr': 0.0001}
07/10/2024 15:56:47 - INFO - root - {'loss': 0.17490620911121368, 'lr': 0.0001}
07/10/2024 15:56:49 - INFO - root - {'loss': 0.4893816113471985, 'lr': 0.0001}
07/10/2024 15:56:51 - INFO - root - {'loss': 0.029585648328065872, 'lr': 0.0001}
07/10/2024 15:56:53 - INFO - root - {'loss': 0.31860917806625366, 'lr': 0.0001}
07/10/2024 15:56:55 - INFO - root - {'loss': 0.5395863056182861, 'lr': 0.0001}
07/10/2024 15:56:57 - INFO - root - {'loss': 0.24320277571678162, 'lr': 0.0001}
07/10/2024 15:56:59 - INFO - root - {'loss': 0.07937968522310257, 'lr': 0.0001}
07/10/2024 15:57:01 - INFO - root - {'loss': 0.03689320385456085, 'lr': 0.0001}
07/10/2024 15:57:04 - INFO - root - {'loss': 0.4648638665676117, 'lr': 0.0001}
07/10/2024 15:57:06 - INFO - root - {'loss': 0.09496625512838364, 'lr': 0.0001}
07/10/2024 15:57:08 - INFO - root - {'loss': 0.14636653661727905, 'lr': 0.0001}
07/10/2024 15:57:10 - INFO - root - {'loss': 0.16717854142189026, 'lr': 0.0001}
07/10/2024 15:57:12 - INFO - root - {'loss': 0.4141579568386078, 'lr': 0.0001}
07/10/2024 15:57:14 - INFO - root - {'loss': 0.1743105947971344, 'lr': 0.0001}
07/10/2024 15:57:16 - INFO - root - {'loss': 0.07635688781738281, 'lr': 0.0001}
